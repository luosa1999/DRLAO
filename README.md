# DRLAO:
  Mobile Edge Computing (MEC), as a real-time computing paradigm extended to the network edge, has been widely adopted. In recent years, Wireless Power Transfer-enabled Mobile Edge Computing (WPT-MEC) has garnered significant attention. However, it is faced with challenges related to offloading strategy formulation and electrical energy resource allocation. Existing solutions exhibit certain limitations. Heuristic methods incur high computational complexity and struggle to adapt to dynamic environments. While Deep Reinforcement Learning (DRL)-based methods continuously refines decisions through interaction with the environment, it demands extensive time and training data. To address these issues, this paper proposes an adaptive algorithm based on DRL, termed DRLAO. This algorithm achieves self-adjustment of parameters, adapts to dynamic changes in the environment, and rapidly makes decisions. DRLAO is comprised of three components: Augmented Deep Neural Network (AugDNN) and Order-Preserving Quantization (KOQ) for addressing offloading decision-making, and Modified Secant Method (MSM) for manipulating electrical energy resource allocation. DRLAO achieves an optimal data processing rate of over 98$\%$ for different WED numbers, and is significantly superior than the baseline algorithm in terms of effectiveness and performance. It also swiftly adapts and converges in dynamic environments with minimal oscillation.
  The code will be released as soon as the paper is accepted.
